(measurements:intro)=
# Introduction

Multi-center studies and data aggregation initiatives have become a standard resource in the field of neuroimaging and a clear prerequisite for the long-term advancement of the field {cite}`horienHitchhikerGuideWorking2021, vanhornItTimeReprioritize2009, lairdLargeOpenDatasets2021`. The creation and utility of such datasets introduces numerous technical and methodological challenges which have become an increasingly popular topic of research, and often debate. However, even if all data is archived, preprocessed, and distributed in a completely tested, reproducible, and documented manner, working with repositories of datasets at a large scale requires compromises to be made. The variability and complexity of MRI acquisition and preprocessing predetermines highly heterogeneous results {cite}`borghiDataManagementSharing2018, gronenschildEffectsFreeSurferVersion2012 , botvinik-nezerVariabilityAnalysisSingle2020`, and it is practically impossible to standardize acquisition protocols and preprocessing procedures across all research centers and application domains. Providing access to raw data, modifying analysis configurations, and integrating new workflows all become increasingly difficult to support with every increase in scale. It is therefore crucial to better understand (and potentially optimize for the minimization of) differences arising from acquisition and preprocessing decisions rather than the studied effects.

Assuming such variation is inherent (and to an extent desirable), it is imperative that the field continuously refines its understanding of the implications of each decision that is made and the significance of various steps and configurations. This study focuses on {{sMRI}} preprocessing, which is the common denominator of the great majority of MRI-based neuroimaging research, and more specifically on the reliability of cross-sectional anatomical statistics calculated with *FreeSurfer*'s recon-all pipeline using a subset of available execution configurations {cite}`fischlFreeSurfer2012`. *FreeSurfer* is a popular and freely available open source neuroimaging toolkit for processing, analyzing, and visualizing human brain {{MR}} images (https://surfer.nmr.mgh.harvard.edu/). It has previously been demonstrated that *FreeSurfer* successfully captures subtle morphological changes in brain structure {cite}`lehmannAtrophyPatternsAlzheimer2010, salatRegionalWhiteMatter2009`, and a number of studies have already pioneered the evaluation of variation originating from differences in *FreeSurfer* versions, operating system, scan session, head-tilt, inter-scan interval, acquisition sequence, and preprocessing stream (cross-sectional vs. longitudinal) {cite}`hedgesReliabilityStructuralMRI2022, gronenschildEffectsFreeSurferVersion2012, knussmannTestretestReliabilityFreeSurferderived2022, hanReliabilityMRIderivedMeasurements2006a, dickersonDetectionCorticalThickness2008, jovicichMRIderivedMeasurementsHuman2009`. Such explorations are key for the sustainability of multi-site collaborations and research leveraging data from heterogeneous sources in the field in general.

The purpose of this study is to expand on previous studies and determine the within-subject reproducibility of *FreeSurfer*-derived anatomical statistics by running a subset of the available execution configurations over a large dataset originating from a single scanner using a consistent acquisition protocol and analyzed on a single server with a particular version of *FreeSurfer*. The importance of exploring these differences between individually processed scans is twofold; first, it is meant to help inform future data harmonization endeavors, and second, to provide a heuristic for "recognizing" subjects across anonymized and preprocessed datasets. In addition, the relationship between within-subject variability and the performance of models for the prediction of sex, age, and {{BMI}} will be evaluated. The assumption underlying this comparison is that an improvement (i.e. reduction) in within-subject variability across sessions implies more reliable results and therefore will result in increased performace.
